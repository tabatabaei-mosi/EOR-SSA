from pathlib import Path

import numpy as np
from sklearn.metrics import confusion_matrix
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall


def path_check(file_path, path_return=False):
    """
    check the path, if it doesn't exist, create it.

    Arguments:
        file_path {str} -- the path should be checked.

    keyword Arguments:
        path_return {bool} -- if the path doesn't exist, return the path string (default: False)

    Returns:
        str -- the path file (if path_return is True)
    """

    # check if the path exist
    path_exist = Path(file_path).exists()

    # if the path doesn't exist, create it
    if not path_exist:
        Path(file_path).mkdir(parents=True)

    # return the created path
    if path_return:
        return file_path


def f1_accuracy(recall, precision):
    """
    f1 score for the model.

    Arguments:
        recall {array-like} -- recall score calculated by the model

        precision {array-like} -- precision score calculated by the model

    Returns:
       array-like -- calculated f1 score for the model
    """

    f1 = 2 * (precision * recall) / (precision + recall)

    return f1


def ann_metrics_history(
    xdata, ydata,
    n_epoch, weights_history, ann_model,
    digit=2,
):
    """
    By using ann weights history (generated by SSA), this function calculates the performance metrics for each epoch.
    The performance metrics include cross-entropy accuracy, recall, precision, and F1 score.
    The dictionary result will use to visualize the performance metrics history.

    Arguments:

        xdata: Input data (x_train).
        ydata: Target data (y_train).
        n_epoch: Number of epochs.
        weights_history: global best weights generated by SSA in each epoch. For each epoch, the weights are stored in a list
            which first element is the weights array and second element is the fitness value.
        ann_model: Artificial neural network model instance (i.e. hybrid model instance)

    Keyword Arguments:

        digit: Number of decimal places to round the performance metrics (default is 2).

    Returns
        A dictionary containing the history (list) of performance metrics.
        The keys are: 'cce_history', 'recall_history', 'precision_history', 'f1_history'
    """

    # Initialize the metrics dictionaries
    metrics_history = {
        "cce_history": [],
        "recall_history": [],
        "precision_history": [],
        "f1_history": []
    }

    # Initialize the metrics objects
    cce = CategoricalAccuracy()
    r = Recall()
    p = Precision()

    # Iterate over the epochs
    for i in range(n_epoch + 1):
        # Calculate the predictions for the current epoch
        yhat = ann_model.prediction(
            solution=weights_history[i][0], x_data=xdata)

        # Update the metrics objects with the current predictions
        cce.update_state(ydata, yhat)
        r.update_state(ydata, yhat)
        p.update_state(ydata, yhat)

        # Calculate and store the metrics for the current epoch
        metrics_history["cce_history"].append(
            round(cce.result().numpy() * 100, digit))
        metrics_history["recall_history"].append(
            round(r.result().numpy() * 100, digit))
        metrics_history["precision_history"].append(
            round(p.result().numpy() * 100, digit))

        # Calculate and store the F1 score for the current epoch
        f1_score = round(f1_accuracy(
            metrics_history["recall_history"][-1], metrics_history["precision_history"][-1]), digit)
        metrics_history["f1_history"].append(f1_score)

        # Reset the metrics objects for the next epoch
        cce.reset_states()
        r.reset_states()
        p.reset_states()

    return metrics_history


def ann_loss_history(
    xdata, ydata,
    n_epoch, weights_history, ann_model,
    digit=2,
):
    """
    By using ann weights history (generated by SSA), this function track the CCE loss for each epoch.
    The result will use to visualize the performance history.

    Arguments:
        xdata {np.ndarray} -- input data (x_train)

        ydata {np.ndarray} -- output data (y_train)

        n_epoch {int} -- number of epochs

        weights_history {np.ndarray} -- global best weights generated by SSA in each epoch. For each epoch, the weights are stored in a list
            which first element is the weights array and second element is the fitness value.

        ann_model {object} -- an instance of hybrid model (Combination of SSA and ANN)

    Keyword Arguments:
        digit {int} -- Number of decimal places to round the performance metrics (default is 2).

    Returns:
        list -- A list containing the CCE loss for each epoch.
    """

    # Initialize the loss history list
    loss_history = []

    # Iterate over the epochs
    for i in range(n_epoch + 1):

        # Calculate the predictions for the current epoch
        yhat = ann_model.prediction(
            solution=weights_history[i][0], x_data=xdata)

        # Calculate the CCE loss for the current epoch
        cce = CategoricalCrossentropy()
        loss = round(cce(ydata, yhat).numpy(), digit)

        # Store the loss for the current epoch
        loss_history.append(loss)

    return loss_history


def best_performance(history, score=False):
    """
    Analyze the history performance of a model (accuracy or loss) by finding the epoch with the best results.

    Arguments:
        history (list): A list of performance metrics (either loss or score) for each epoch.

    Keyword Arguments:
        score (bool, optional): Set to True if the history represents scores.
        Default is False, which assumes the history represents loss values.

    Returns:
        dict: A dictionary containing the best performance metric and the corresponding epoch index.
        The keys are: 'best_metric', 'best_epoch'
    """
    # Find the best performance metric (min_loss or max_score) and its index
    if score:
        best_metric, best_index = max((val, idx)
                                      for idx, val in enumerate(history))
    else:
        best_metric, best_index = min((val, idx)
                                      for idx, val in enumerate(history))

    # Round the best performance metric to 3 decimal places
    best_metric = round(best_metric, 3)

    # Return the results in a dictionary
    return {'best_metric': best_metric, 'best_epoch': best_index}


def decode_label(output_codes, re_group=False):
    """
    decode the label code (retruned by model or true outputs) to the true label (EOR method).
    The results of this function is used for plotting the confusion matrix.

    Arguments:
        output_codes {set} -- the label codes returned by the model (true or predicted output)

    Keyword Arguments:
        re_group {bool} -- If the data is re-grouped to contain only 3 EOR category to balance dataset (default: True)

    Returns:
        list -- the true label of the EOR methods (The real name of the EOR methods) 
    """

    # The list of true label of the EOR methods
    decode_ouputs = list()

    if re_group:
        # If re-grouped strategy is used
        true_label = ['Thermal methods',
                      'Gas miscible/im.', 'Chemical and others']

    else:
        # The whole list of EOR methods in dataset (sorted in a list according to the code assigned to each method)
        true_label = [
            'Steam', 'HW', 'Combustion', 'CO2 mis', 'CO2 immis',
            'H mis', 'H immis', 'N immi', 'Polymer',
            'AGM', 'Microbial', 'Cyclic steam', 'HC mis/Water', 'AGA', 'Steam-SAGD'
        ]

    # Decode the label code to the true label
    for code in output_codes:
        decode_ouputs.append(true_label[code])

    return decode_ouputs


def conf_matrix(
    xdata, ydata,
    n_epoch, ann_model,
    weights_history,
    history=False, Category=False
):
    """
    Compute confusion matrix for the given data and model over the history or just for the last epoch.
    Moreover, find the EOR labels used by model for visulization


    Arguments:
        xdata (array-like): Input data
        ydata (array-like): True output data
        n_epoch (int): Number of epochs
        ann_model (object): An instance of hybrid model (Combination of SSA and ANN)
        weights_history (array-like): global best weights generated by SSA in each epoch. For each epoch, the weights are stored in a list
            which first element is the weights array and second element is the fitness value.

    Keyword Arguments:
        history (bool, optional): If True, compute confusion matrix and EOR labels for each epoch, else just for the last epoch. Defaults to False.
        Category (bool, optional): If True, use re-grouped labels (3 Categories). Defaults to False (All the EOR labels).

    Returns:
        tuple: If history is True, return a tuple of two lists. 
        The first list contains the confusion matrix for each epoch, and the second list contains the EOR labels for each epoch.
        otherwise (history=False), return a tuple of two arrays (confusion matrix and EOR labels)
    """

    # Function to process predictions and true labels
    def process_predictions(y_hat, y_true):
        """
        process over the y_true and y_predict to find the real EOR label. 
        Additionally, calculate the confusion matrix

        Arguments:
            y_hat {array-like} -- y_hat (final result of model by argmax)
            y_true {array-like} -- y_true (true label of the data)

        Returns:
            tuple -- confusion matrix and the real EOR label 
        """
        # the set of unique label codes
        class_code_true = set(y_true)
        class_code_pre = set(y_hat)

        # combine the two sets to get the unique labels
        class_code = class_code_true | class_code_pre

        # decode the label code to the real EOR label
        class_label = decode_label(class_code, Category)

        # Calculate confusion matrix
        c_matrix = confusion_matrix(y_true, y_hat)

        return c_matrix, class_label

    if history:
        # Initialize a list to store confusion matrices
        conf_matrix_history = list()

        # Loop over epochs
        for i in range(n_epoch + 1):
            # Predict labels using the ANN model
            predicted_output = ann_model.prediction(
                solution=weights_history[i][0], x_data=xdata)

            # argmax to get the class index (round the output to an available category)
            predicted_class_indices = np.argmax(predicted_output, axis=1)
            true_output_indices = np.argmax(ydata, axis=1)

            # Process predictions and true labels to get confusion matrix and EOR labels
            c_matrix, class_label = process_predictions(
                predicted_class_indices, true_output_indices)

            # Append confusion matrix to the list
            conf_matrix_history.append(c_matrix)

        return conf_matrix_history, class_label

    else:
        # Predict labels using the ANN model
        predicted_output = ann_model.prediction(
            solution=weights_history[-1][0], x_data=xdata)

        # argmax to get the class index (round the output to an available category)
        predicted_class_indices = np.argmax(predicted_output, axis=1)
        true_output_indices = np.argmax(ydata, axis=1)

        # Process predictions and true labels to get confusion matrix and EOR labels
        c_matrix, class_label = process_predictions(
            predicted_class_indices, true_output_indices)

        return c_matrix, class_label
